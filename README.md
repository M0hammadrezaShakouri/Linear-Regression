# Linear Regression using Stochastic Gradient Descent and Batch Gradient Descent

## Objective
Implementing Stochastic Gradient Descent (SGD) and Batch Gradient Descent algorithms for linear regression on datasets containing information about height, weight, and sex of random individuals. Two datasets were used - one with normal data and the other with outliers.

## Tasks

1. **Data Normalization:**
   - Normalize the datasets to ensure that the values of each feature range between 0 (minimum value) and 1 (maximum value).

2. **Model Training:**
   - Implement SGD and Batch Gradient Descent algorithms with 2000 epochs for each.
   - Train the models separately on the normalized datasets.

3. **Visualization:**
   - Plot the original datasets alongside the obtained regression models.
   - Use the height feature for the X-axis and the weight feature for the Y-axis.
   - Differentiate between males and females by employing distinct colors in the plots.

## Dataset Description
- Two datasets used: one normal and one with outliers.
- Features: Height (X) and Weight (Y).
- Outliers included to challenge the robustness of the implemented algorithms.

## Implementation Details
- Stochastic Gradient Descent: 2000 epochs.
- Batch Gradient Descent: 2000 epochs.

## Plotting
- X-axis: Height feature.
- Y-axis: Weight feature.
- Discrimination between males and females using different colors in the plots.

## Result
The visual representation of the datasets and regression models provides insights into the effectiveness and robustness of Stochastic and Batch Gradient Descent in handling linear regression tasks, especially in the presence of outliers.



